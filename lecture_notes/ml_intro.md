# Основные понятия ML

# Что такое машинное обучение,

## Область применения,

Машинное обучение (от англ. *machine learning*) – это область знаний на стыке линейной алгебры, теории вероятностей и методов оптимизации.

Говорят, что модель обучается на опыте $E$ относительно класса задач $T$ в смысле меры качества $L$, если при решении задачи $T$ качество, измеряемое мерой $L$ , возрастает при демонстрации нового опыта $D$.

Говоря простым языком, если правильным образом разработать процесс *анализа* поступающих в систему машинного обучения данных, то система сможет проводить аналогичную обработку без участия разработчика.

Алгоритмы ML используются везде, где нужно автоматизировано (т.е. в большом количестве) принимать решения:

* вычисление *спам-писем* в почте
* *рекомендации* товаров в онлайн-ритейле (блок "с этим товаром покупают")
* подбор музыки на основании *вкусов пользователя*
* детекция *эротических или жестоких* сцен в видео контенте
* распознавание аудио-сигнала речи (привет, Алиса!)
* трейдинг - поиск патернов и закономерностей


Зачем нужно разрабатывать ML проекты, когда в каждой из областей есть экспертные знания?

* сложно придумать правила  в понятном человеку виде (например, распознавание изображений)
* эвристики устаревают и нужно придумывать новые (борьба со спамом - непрерывный процесс)

## Этапы ML проекта

Допустим, вы хотите решить какую-то задачу (например, выявление спам-писем в почте) с помощью ML. На какие этапы можно декомпозировать задачу:
1. Выгрузка **обучающей выборки** (например, набор писем за прошлый месяц)
1. **Разметка** обучающей выборки (отметить те, которые являются спамом). Некоторые алгоритмы могут работать и без разметки. Разметка - это таргет.
1. Выбираем **метрику качества** решения задачи (долю точно определённых спам писем и не-спам писем)
1. Каждый объект выборки описываем некоторыми **признаками** (называют по кальке с англ **фичами**)
1. **Настраиваем** выбранную модель машинного обучения наилучшим образом решать поставленную задачу - делать прогноз по фичам
1. Применяем модель к **новым данным** (этот этап называется *эксплуатация*)

“Разметить” обучающую выборку значит “проставить каждому объекту обучающей выборки целевую переменную”. Алгоритмы ML, которые используют разметку, относятся к семейству **supervised learning**

Целевая переменная (**target**) - это величина, которую хотим предсказывать. Иногда таргет бывает **дискретный** или **непрерывный**

Дискретный таргет - задача **классификации объектов** (англ *classification*)

* отправить письмо в спам или не спам - таргет **0** или **1**
* клиент банка вернёт кредит вовремя, доспустит просрочку платежа или вообще не вернёт (наступит дефолт) - таргет **0**, **1** или **2**
* трансформировать аудио-запись в текст - таргет $0,\ldots ,N$ (соответствует мощности словаря) 

Непрерывный таргет - задача **регрессии** (англ regression)
* предсказать арендную цену квартиры по фото и описанию в тыс. рублей (как на Циан)
* уровень пульса по данным с фитнес браслета
* сколько лайков соберёт фотография в соцсети

## Формальное определение ML

Модель машинного обучения в общем случае  - это семейство алгоритмов $h(x, \theta): X \times \Theta \rightarrow Y$. Процесс машинного обучения сводится к тому, чтобы по опыту (обучающей выборке) $D$ подобрать такую функцию $h(\cdot)$, что мера качества $L$ будет максимальной, т.е. из семейства алгоритмов нам нужно выбрать один конкретный пример.

$X$ - наша обучающая выборка. Выборку удобно представлять в виде матрицы *объекты-признаки* (по строкам объекты, по столбцам признаки)

В процессе обучения мы выбираем функцию из семейства $h(\cdot)$, которая наилучшим образом описывает наши данные.
Наилучшая функция из семейства h - это та функция, при которой минимума достигает **эмпирический риск**.  Эмпирический риск - усредненное значение функции потерь на всей обучающей выборке. 

Как посчитать эмпирический риск? Для этого вводим понятие *функции потерь*.

**Loss function**  (функция потерь) - функция, которая принимает на вход таргет и предсказания модели, а возвращает единственное число - loss. Говорят, что процесс обучения модели - это оптимизация функции потерь, поиск её минимума.

**Metric** (метрика) - это тоже функция, но она не оптимизируется моделью, хотя и позволяет сделать выводы о качестве модели.

Например для задачи линейной регрессии, которую мы обсудим на семинаре функция потерь называется **squared error**, где $w$ - параметры модели

$$
\left(y_i -  \sum_{j=1}^{n}w_jx_i^j\right)^2
$$

Фичи (признаки) можно разделить на три больших категории
* бинарные (boolean): True/False, 1/0
* категориальные (categorical), иногда говорят дискретные: сутки можно разделить на три категориальных фичи (morning, day night)
* непрерывные (numerical): количество звонков поступающих в коллцентр
Придумать значимые фичи для задачи - это 90% успеха.

Последний важный термин в этом разделе - **обобщающая способность**. Это способность модели корректно работать на новых данных

ML обучается на исторических данных данных, а применяется на новых
Валидация - процедура эмпирического оценивания обобщающей способности моделей. Мы скрываем от модели часть датасета (трейн) и проверяем качество на контроле.


## Термины ML на примере линейной регрессии

Задача *линейной* регресии: восстановить на функцию $h(x_i)$ в виде *линейной комбинации* (т.е. суммы с некоторыми весами *важности*) признаков объекта. Сами признаки называются *предикторами*:,
$$
\forall x_i: h(x) = w_0 + w_1x_i^1 + \ldots + w_nx_i^n = \sum_{j=1}^{n}w_jx_i^j = \overline{x}_i^T\overline{w},
$$

К признаковому пространству добавляется "фиктивный" признак $x_0=1$, "важность" которого сохраняется в коэффициент $w_0$.

Мера качества $L$ для задачи регрессии - квадрат разности между фактическим значением и прогнозом. ,
$$
L(h(x_i, \theta), y_i) = \left(y_i - h(x_i, \theta)\right)^2 = \left(y_i -  \sum_{j=1}^{n}w_jx_i^j\right)^2,
$$

Эмпирический риск это значение меры качества по всей обучающей выборке, то есть вычисляется по формуле по формуле 

$$
Q_{\text{emp}}(h) = \frac{1}{N}\sum_{i=1}^{N}L(h(x_i, \theta), y_i)
$$